# Copyright 2017, 2020, 2023, 2024 IBM Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.

name=mq-sink
connector.class=com.ibm.eventstreams.connect.mqsink.MQSinkConnector

# You can increase this for higher throughput
tasks.max=1

# The list of source Kafka topics
topics=

# The name of the MQ queue manager - required
mq.queue.manager=

# The connection mode to connect to MQ - client (default) or bindings - optional
# mq.connection.mode=client
# mq.connection.mode=bindings

# A list of one or more host(port) entries for connecting to the queue manager. Entries are separated with a comma - required (unless using bindings or CCDT)
mq.connection.name.list=

# The name of the server-connection channel - required (unless using bindings or CCDT)
mq.channel.name=

# The name of the target MQ queue - required
mq.queue=

# The user name for authenticating with the queue manager - optional
# mq.user.name=

# The password for authenticating with the queue manager - optional
# mq.password=

# Alternatively can use a ConfigProvider for externalising secrets (see README.md for more details)
# Variable references are of the form ${provider:[path:]key} where the path is optional,
# depending on the ConfigProvider implementation.
# mq.password=${file:/var/run/secret.properties:secret-key}

# Whether to use MQ connection security parameters (MQCSP) to provide credentials - optional
# mq.user.authentication.mqcsp=

# The CCDT URL to use to establish a connection to the queue manager - optional
# mq.ccdt.url=

# The message builders control conversion of data between the internal Kafka Connect representation and the messages in MQ - required
mq.message.builder=com.ibm.eventstreams.connect.mqsink.builders.DefaultMessageBuilder
# mq.message.builder=com.ibm.eventstreams.connect.mqsink.builders.JsonMessageBuilder
# mq.message.builder=com.ibm.eventstreams.connect.mqsink.builders.ConverterMessageBuilder

# Whether to generate the message body as a JMS message type, default false - optional
# mq.message.body.jms=

# Time-to-live in milliseconds for messages sent to MQ, default 0 (unlimited) - optional
# mq.time.to.live=

# Send persistent or non-persistent messages to MQ, default true - optional
# mq.persistent=

# The name of the cipher suite for TLS (SSL) connection (default blank, meaning do not use TLS) - optional
# See https://www.ibm.com/support/knowledgecenter/en/SSFKSJ_9.1.0/com.ibm.mq.dev.doc/q113220_.htm for valid values
# mq.ssl.cipher.suite=

# The distinguished name pattern of the TLS (SSL) peer - optional
# mq.ssl.peer.name=

# Location and password for the keystore and truststore for SSL (TLS) connections
# mq.ssl.keystore.location=
# mq.ssl.keystore.password=
# mq.ssl.truststore.location=
# mq.ssl.truststore.password=

# Whether to set system property to control use of IBM cipher mappings - optional
# mq.ssl.use.ibm.cipher.mappings=false

# The JMS message header to set from the Kafka record key - optional
# Valid value is JMSCorrelationID
# Don't forget to set key.converter to a compatible converter as described in README.md
# mq.message.builder.key.header=JMSCorrelationID

# The JMS properties to set from the Kafka topic, partition and offset - optional
# mq.message.builder.topic.property=
# mq.message.builder.partition.property=
# mq.message.builder.offset.property=

# The name of the reply-to queue - optional
# Specify either just the queue name, or a URI of the form queue://<qmgr>/<queue>
# mq.reply.queue=

# The converters control conversion of data between the internal Kafka Connect representation and the messages in Kafka.
# key.converter=org.apache.kafka.connect.converters.ByteArrayConverter
key.converter=org.apache.kafka.connect.storage.StringConverter
# key.converter=org.apache.kafka.connect.json.JsonConverter

# value.converter=org.apache.kafka.connect.converters.ByteArrayConverter
value.converter=org.apache.kafka.connect.storage.StringConverter
# value.converter=org.apache.kafka.connect.json.JsonConverter
